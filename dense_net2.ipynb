{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3.5","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"dense_net.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"yJxfH7WgPqd6","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np\n","\n","import timeit"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMq1nbJSPyND","colab_type":"code","outputId":"173c22bd-ce58-4e31-a75f-e1a718442b7d","executionInfo":{"status":"ok","timestamp":1588166526486,"user_tz":-480,"elapsed":14549,"user":{"displayName":"517613021@qq.com","photoUrl":"","userId":"10807275253709735297"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","!tar xzf cifar-10-python.tar.gz"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-04-29 13:21:56--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170498071 (163M) [application/x-gzip]\n","Saving to: ‘cifar-10-python.tar.gz’\n","\n","cifar-10-python.tar 100%[===================>] 162.60M  24.9MB/s    in 7.2s    \n","\n","2020-04-29 13:22:04 (22.4 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fwm-IXV1Pqd_","colab_type":"code","colab":{}},"source":["class ChunkSampler(sampler.Sampler):\n","    \"\"\"Samples elements sequentially from some offset. \n","    Arguments:\n","        num_samples: # of desired datapoints\n","        start: offset where we should start selecting from\n","    \"\"\"\n","    def __init__(self, num_samples, start = 0):\n","        self.num_samples = num_samples\n","        self.start = start\n","\n","    def __iter__(self):\n","        return iter(range(self.start, self.start + self.num_samples))\n","\n","    def __len__(self):\n","        return self.num_samples\n","\n","NUM_TRAIN = 49000\n","NUM_VAL = 1000\n","\n","cifar10_train = dset.CIFAR10('/content/', train=True, download=False,\n","                           transform=T.ToTensor())\n","loader_train = DataLoader(cifar10_train, batch_size=128, sampler=ChunkSampler(NUM_TRAIN, 0))\n","\n","cifar10_val = dset.CIFAR10('/content/', train=True, download=False,\n","                           transform=T.ToTensor())\n","loader_val = DataLoader(cifar10_val, batch_size=128, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n","\n","cifar10_test = dset.CIFAR10('/content/', train=False, download=False,\n","                          transform=T.ToTensor())\n","loader_test = DataLoader(cifar10_test, batch_size=128)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHobz-oUPqeD","colab_type":"code","colab":{}},"source":["dtype = torch.FloatTensor # the CPU datatype\n","\n","# Constant to control how frequently we print train loss\n","print_every = 100\n","\n","# This is a little utility that we'll use to reset the model\n","# if we want to re-initialize all our parameters\n","def reset(m):\n","    if hasattr(m, 'reset_parameters'):\n","        m.reset_parameters()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eY3afDLuPqeG","colab_type":"code","colab":{}},"source":["class Flatten(nn.Module):\n","    def forward(self, x):\n","        N, C, H, W = x.size() # read in N, C, H, W\n","        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"olw200ViPqeK","colab_type":"code","colab":{}},"source":["# Verify that CUDA is properly configured and you have a GPU available\n","\n","torch.cuda.is_available()\n","gpu_dtype = torch.cuda.FloatTensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Rr2lPxLFTo8","colab_type":"code","colab":{}},"source":["import random\n","def random_flip(img):\n","    x_flip = random.choice([True, False])\n","    img = img.numpy()\n","    if x_flip:\n","        img = img[:, ::-1, :]\n","    return torch.from_numpy(img.copy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyNxqMoTPqeN","colab_type":"code","colab":{}},"source":["def train(model, loss_fn, optimizer, num_epochs = 1):\n","    best_val_acc = 0\n","    for epoch in range(num_epochs):\n","        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n","        model.train()\n","        for t, (x, y) in enumerate(loader_train):\n","            x = random_flip(x)\n","            x_var = Variable(x.type(gpu_dtype))\n","            y_var = Variable(y.type(gpu_dtype).long())\n","\n","            scores = model(x_var)\n","            \n","            loss = loss_fn(scores, y_var)\n","            if (t + 1) % print_every == 0:\n","                print('t = %d, loss = %.4f' % (t + 1, loss.data))\n","                \n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        if epoch % 10 == 0 and epoch > 10:\n","          val_acc = check_accuracy(model, loader_val)\n","          if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            best_model = model\n","          else:\n","            model = best_model\n","        if epoch % 30 == 0 and epoch > 10:\n","          save(best_model)\n","\n","def check_accuracy(model, loader):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')   \n","    num_correct = 0\n","    num_samples = 0\n","    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n","    for x, y in loader:\n","        x_var = Variable(x.type(gpu_dtype), volatile=True)\n","\n","        scores = model(x_var)\n","        _, preds = scores.data.cpu().max(1)\n","        num_correct += (preds == y).sum()\n","        num_samples += preds.size(0)\n","    acc = float(num_correct) / num_samples\n","    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n","    return acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTz1iSDRPM3n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"448c7d76-f55c-4953-b59c-2bf8efbd8902","executionInfo":{"status":"ok","timestamp":1588168838835,"user_tz":-480,"elapsed":31097,"user":{"displayName":"517613021@qq.com","photoUrl":"","userId":"10807275253709735297"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lSObhSgOPqeR","colab_type":"code","colab":{}},"source":["class Bottleneck(nn.Module):\n","    def __init__(self, in_dims, growth_rate):\n","        super(Bottleneck, self).__init__()\n","        self.block = nn.Sequential(\n","        nn.BatchNorm2d(in_dims),\n","        nn.ReLU(),\n","        nn.Conv2d(in_dims, 4 * growth_rate, kernel_size=1),\n","            \n","        nn.BatchNorm2d(4 * growth_rate),\n","        nn.ReLU(),\n","        nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1))\n","        \n","    def forward(self, x):\n","        out = self.block(x)\n","        #print(x.shape)\n","        #print(out.shape)\n","        out = torch.cat([out, x], 1)\n","        return out\n","\n","class Transition(nn.Module):\n","    def __init__(self, in_dims, out_dims):\n","        super(Transition, self).__init__()\n","        self.trans = nn.Sequential(\n","        nn.BatchNorm2d(in_dims),\n","        nn.ReLU(),\n","        nn.Conv2d(in_dims, out_dims, kernel_size=1),\n","        nn.AvgPool2d(2))\n","    \n","    def forward(self, x):\n","        return self.trans(x)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6aX7lSqNK7fC","colab_type":"code","colab":{}},"source":["import time\n","def save(model):\n","  save_dict = dict()\n","  save_dict['model'] = model.state_dict()\n","  timestr = time.strftime('%m%d%H%M')\n","  save_path = 'densenet_%s' % timestr\n","  torch.save(save_dict, save_path)\n","  return save_path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMstvN8RPqeV","colab_type":"code","outputId":"2ffd4e41-cba1-42e8-f953-a50fa4101254","executionInfo":{"status":"ok","timestamp":1588193439724,"user_tz":-480,"elapsed":5504348,"user":{"displayName":"517613021@qq.com","photoUrl":"","userId":"10807275253709735297"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["nblocks = [6, 12, 24, 16]\n","learning_rate=0.01\n","\n","class DenseNet(nn.Module):\n","    def __init__(self, block, trans, nblocks, growth_rate=12, theta=0.5, num_classes=10):\n","        super(DenseNet, self).__init__()\n","        \n","        in_dims = 2*growth_rate\n","        self.dense1 = self.dense_block(block, nblocks[0], in_dims, growth_rate)\n","        in_dims += int(nblocks[0] * growth_rate)\n","        out_dims = int(in_dims * theta)\n","        self.trans1 = trans(in_dims, out_dims)\n","        in_dims = out_dims\n","        \n","        self.dense2 = self.dense_block(block, nblocks[1], in_dims, growth_rate)\n","        in_dims += int(nblocks[1] * growth_rate)\n","        out_dims = int(in_dims * theta)\n","        self.trans2 = trans(in_dims, out_dims)\n","        in_dims = out_dims\n","        \n","        self.dense3 = self.dense_block(block, nblocks[2], in_dims, growth_rate)\n","        in_dims += int(nblocks[2] * growth_rate)\n","        out_dims = int(in_dims * theta)\n","        self.trans3 = trans(in_dims, out_dims)\n","        in_dims = out_dims\n","        \n","        self.dense4 = self.dense_block(block, nblocks[3], in_dims, growth_rate)\n","        in_dims += int(nblocks[3] * growth_rate)\n","        \n","        self.dense_net = nn.Sequential(\n","            nn.Conv2d(3, 2 * growth_rate, kernel_size=3, padding=1),\n","            self.dense1,\n","            self.trans1,\n","            self.dense2,\n","            self.trans2,\n","            self.dense3,\n","            self.trans3,\n","            self.dense4,\n","            nn.BatchNorm2d(in_dims),\n","            nn.ReLU(),\n","            nn.AvgPool2d(4),\n","            Flatten(),\n","            nn.Linear(in_dims, num_classes)\n","        )\n","        \n","    def dense_block(self, block, num_blocks, in_dims, growth_rate):\n","        layers = []\n","        for i in range(num_blocks):\n","            layers.append(block(in_dims, growth_rate))\n","            in_dims += growth_rate\n","        return nn.Sequential(* layers)\n","    \n","    def forward(self, x):\n","        #print(x.shape)\n","        out = self.dense_net(x)\n","        return out\n","\n","model = DenseNet(Bottleneck, Transition,nblocks)\n","model.type(gpu_dtype)\n","\n","loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)# lr sets the learning rate of the optimizer\n","train(model, loss_fn, optimizer, num_epochs=150)\n","check_accuracy(model, loader_val)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Starting epoch 1 / 150\n","t = 100, loss = 2.0221\n","t = 200, loss = 1.5943\n","t = 300, loss = 1.4866\n","Starting epoch 2 / 150\n","t = 100, loss = 1.2277\n","t = 200, loss = 1.0536\n","t = 300, loss = 1.0192\n","Starting epoch 3 / 150\n","t = 100, loss = 0.9096\n","t = 200, loss = 0.8341\n","t = 300, loss = 0.8228\n","Starting epoch 4 / 150\n","t = 100, loss = 0.7682\n","t = 200, loss = 0.6760\n","t = 300, loss = 0.6118\n","Starting epoch 5 / 150\n","t = 100, loss = 0.6457\n","t = 200, loss = 0.5748\n","t = 300, loss = 0.4614\n","Starting epoch 6 / 150\n","t = 100, loss = 0.5179\n","t = 200, loss = 0.5014\n","t = 300, loss = 0.4045\n","Starting epoch 7 / 150\n","t = 100, loss = 0.4144\n","t = 200, loss = 0.3908\n","t = 300, loss = 0.2928\n","Starting epoch 8 / 150\n","t = 100, loss = 0.3625\n","t = 200, loss = 0.3297\n","t = 300, loss = 0.2403\n","Starting epoch 9 / 150\n","t = 100, loss = 0.2880\n","t = 200, loss = 0.3287\n","t = 300, loss = 0.2356\n","Starting epoch 10 / 150\n","t = 100, loss = 0.2394\n","t = 200, loss = 0.2074\n","t = 300, loss = 0.1872\n","Starting epoch 11 / 150\n","t = 100, loss = 0.1613\n","t = 200, loss = 0.2219\n","t = 300, loss = 0.1699\n","Starting epoch 12 / 150\n","t = 100, loss = 0.1681\n","t = 200, loss = 0.1901\n","t = 300, loss = 0.1463\n","Starting epoch 13 / 150\n","t = 100, loss = 0.1579\n","t = 200, loss = 0.1070\n","t = 300, loss = 0.1164\n","Starting epoch 14 / 150\n","t = 100, loss = 0.1129\n","t = 200, loss = 0.1078\n","t = 300, loss = 0.1246\n","Starting epoch 15 / 150\n","t = 100, loss = 0.0721\n","t = 200, loss = 0.1156\n","t = 300, loss = 0.0611\n","Starting epoch 16 / 150\n","t = 100, loss = 0.1089\n","t = 200, loss = 0.1116\n","t = 300, loss = 0.0703\n","Starting epoch 17 / 150\n","t = 100, loss = 0.2330\n","t = 200, loss = 0.0763\n","t = 300, loss = 0.0757\n","Starting epoch 18 / 150\n","t = 100, loss = 0.0506\n","t = 200, loss = 0.1130\n","t = 300, loss = 0.0950\n","Starting epoch 19 / 150\n","t = 100, loss = 0.0542\n","t = 200, loss = 0.1618\n","t = 300, loss = 0.0351\n","Starting epoch 20 / 150\n","t = 100, loss = 0.0596\n","t = 200, loss = 0.0831\n","t = 300, loss = 0.0748\n","Starting epoch 21 / 150\n","t = 100, loss = 0.1839\n","t = 200, loss = 0.0729\n","t = 300, loss = 0.0166\n","Checking accuracy on validation set\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Got 828 / 1000 correct (82.80)\n","Starting epoch 22 / 150\n","t = 100, loss = 0.1005\n","t = 200, loss = 0.1873\n","t = 300, loss = 0.0154\n","Starting epoch 23 / 150\n","t = 100, loss = 0.0994\n","t = 200, loss = 0.0144\n","t = 300, loss = 0.0910\n","Starting epoch 24 / 150\n","t = 100, loss = 0.0532\n","t = 200, loss = 0.0893\n","t = 300, loss = 0.0170\n","Starting epoch 25 / 150\n","t = 100, loss = 0.0276\n","t = 200, loss = 0.0399\n","t = 300, loss = 0.0610\n","Starting epoch 26 / 150\n","t = 100, loss = 0.0223\n","t = 200, loss = 0.0459\n","t = 300, loss = 0.0829\n","Starting epoch 27 / 150\n","t = 100, loss = 0.0460\n","t = 200, loss = 0.0571\n","t = 300, loss = 0.0525\n","Starting epoch 28 / 150\n","t = 100, loss = 0.0701\n","t = 200, loss = 0.0156\n","t = 300, loss = 0.0642\n","Starting epoch 29 / 150\n","t = 100, loss = 0.0371\n","t = 200, loss = 0.0070\n","t = 300, loss = 0.0178\n","Starting epoch 30 / 150\n","t = 100, loss = 0.0301\n","t = 200, loss = 0.0261\n","t = 300, loss = 0.0427\n","Starting epoch 31 / 150\n","t = 100, loss = 0.0169\n","t = 200, loss = 0.0349\n","t = 300, loss = 0.0158\n","Checking accuracy on validation set\n","Got 841 / 1000 correct (84.10)\n","Starting epoch 32 / 150\n","t = 100, loss = 0.0140\n","t = 200, loss = 0.0671\n","t = 300, loss = 0.0288\n","Starting epoch 33 / 150\n","t = 100, loss = 0.0704\n","t = 200, loss = 0.0065\n","t = 300, loss = 0.0172\n","Starting epoch 34 / 150\n","t = 100, loss = 0.0256\n","t = 200, loss = 0.0246\n","t = 300, loss = 0.0159\n","Starting epoch 35 / 150\n","t = 100, loss = 0.0342\n","t = 200, loss = 0.0216\n","t = 300, loss = 0.0354\n","Starting epoch 36 / 150\n","t = 100, loss = 0.0250\n","t = 200, loss = 0.2038\n","t = 300, loss = 0.0226\n","Starting epoch 37 / 150\n","t = 100, loss = 0.0509\n","t = 200, loss = 0.0295\n","t = 300, loss = 0.1241\n","Starting epoch 38 / 150\n","t = 100, loss = 0.0235\n","t = 200, loss = 0.0434\n","t = 300, loss = 0.0306\n","Starting epoch 39 / 150\n","t = 100, loss = 0.0231\n","t = 200, loss = 0.1515\n","t = 300, loss = 0.0107\n","Starting epoch 40 / 150\n","t = 100, loss = 0.0139\n","t = 200, loss = 0.0198\n","t = 300, loss = 0.0382\n","Starting epoch 41 / 150\n","t = 100, loss = 0.0261\n","t = 200, loss = 0.0097\n","t = 300, loss = 0.0085\n","Checking accuracy on validation set\n","Got 837 / 1000 correct (83.70)\n","Starting epoch 42 / 150\n","t = 100, loss = 0.0310\n","t = 200, loss = 0.0110\n","t = 300, loss = 0.0561\n","Starting epoch 43 / 150\n","t = 100, loss = 0.0865\n","t = 200, loss = 0.0130\n","t = 300, loss = 0.0341\n","Starting epoch 44 / 150\n","t = 100, loss = 0.0372\n","t = 200, loss = 0.0259\n","t = 300, loss = 0.0157\n","Starting epoch 45 / 150\n","t = 100, loss = 0.0185\n","t = 200, loss = 0.0274\n","t = 300, loss = 0.0146\n","Starting epoch 46 / 150\n","t = 100, loss = 0.0244\n","t = 200, loss = 0.0046\n","t = 300, loss = 0.0315\n","Starting epoch 47 / 150\n","t = 100, loss = 0.0177\n","t = 200, loss = 0.0421\n","t = 300, loss = 0.0117\n","Starting epoch 48 / 150\n","t = 100, loss = 0.0333\n","t = 200, loss = 0.0511\n","t = 300, loss = 0.0094\n","Starting epoch 49 / 150\n","t = 100, loss = 0.0133\n","t = 200, loss = 0.0105\n","t = 300, loss = 0.0248\n","Starting epoch 50 / 150\n","t = 100, loss = 0.0246\n","t = 200, loss = 0.0262\n","t = 300, loss = 0.0185\n","Starting epoch 51 / 150\n","t = 100, loss = 0.0147\n","t = 200, loss = 0.0052\n","t = 300, loss = 0.0038\n","Checking accuracy on validation set\n","Got 847 / 1000 correct (84.70)\n","Starting epoch 52 / 150\n","t = 100, loss = 0.0343\n","t = 200, loss = 0.0325\n","t = 300, loss = 0.0517\n","Starting epoch 53 / 150\n","t = 100, loss = 0.0199\n","t = 200, loss = 0.0685\n","t = 300, loss = 0.0026\n","Starting epoch 54 / 150\n","t = 100, loss = 0.0071\n","t = 200, loss = 0.0180\n","t = 300, loss = 0.0471\n","Starting epoch 55 / 150\n","t = 100, loss = 0.0256\n","t = 200, loss = 0.0260\n","t = 300, loss = 0.0221\n","Starting epoch 56 / 150\n","t = 100, loss = 0.0481\n","t = 200, loss = 0.0397\n","t = 300, loss = 0.0008\n","Starting epoch 57 / 150\n","t = 100, loss = 0.0325\n","t = 200, loss = 0.0112\n","t = 300, loss = 0.0739\n","Starting epoch 58 / 150\n","t = 100, loss = 0.0170\n","t = 200, loss = 0.0332\n","t = 300, loss = 0.0429\n","Starting epoch 59 / 150\n","t = 100, loss = 0.0704\n","t = 200, loss = 0.0303\n","t = 300, loss = 0.0383\n","Starting epoch 60 / 150\n","t = 100, loss = 0.0226\n","t = 200, loss = 0.0145\n","t = 300, loss = 0.0060\n","Starting epoch 61 / 150\n","t = 100, loss = 0.0568\n","t = 200, loss = 0.0388\n","t = 300, loss = 0.0320\n","Checking accuracy on validation set\n","Got 852 / 1000 correct (85.20)\n","Starting epoch 62 / 150\n","t = 100, loss = 0.0053\n","t = 200, loss = 0.0029\n","t = 300, loss = 0.0310\n","Starting epoch 63 / 150\n","t = 100, loss = 0.0052\n","t = 200, loss = 0.0294\n","t = 300, loss = 0.0852\n","Starting epoch 64 / 150\n","t = 100, loss = 0.0159\n","t = 200, loss = 0.0021\n","t = 300, loss = 0.0123\n","Starting epoch 65 / 150\n","t = 100, loss = 0.0069\n","t = 200, loss = 0.0018\n","t = 300, loss = 0.0458\n","Starting epoch 66 / 150\n","t = 100, loss = 0.0515\n","t = 200, loss = 0.0152\n","t = 300, loss = 0.0235\n","Starting epoch 67 / 150\n","t = 100, loss = 0.0147\n","t = 200, loss = 0.0025\n","t = 300, loss = 0.0411\n","Starting epoch 68 / 150\n","t = 100, loss = 0.0085\n","t = 200, loss = 0.0364\n","t = 300, loss = 0.0012\n","Starting epoch 69 / 150\n","t = 100, loss = 0.0061\n","t = 200, loss = 0.0220\n","t = 300, loss = 0.0022\n","Starting epoch 70 / 150\n","t = 100, loss = 0.0297\n","t = 200, loss = 0.0240\n","t = 300, loss = 0.0120\n","Starting epoch 71 / 150\n","t = 100, loss = 0.0252\n","t = 200, loss = 0.0625\n","t = 300, loss = 0.0073\n","Checking accuracy on validation set\n","Got 870 / 1000 correct (87.00)\n","Starting epoch 72 / 150\n","t = 100, loss = 0.0021\n","t = 200, loss = 0.0081\n","t = 300, loss = 0.0036\n","Starting epoch 73 / 150\n","t = 100, loss = 0.0352\n","t = 200, loss = 0.0280\n","t = 300, loss = 0.0285\n","Starting epoch 74 / 150\n","t = 100, loss = 0.0085\n","t = 200, loss = 0.0309\n","t = 300, loss = 0.0193\n","Starting epoch 75 / 150\n","t = 100, loss = 0.0117\n","t = 200, loss = 0.0229\n","t = 300, loss = 0.0043\n","Starting epoch 76 / 150\n","t = 100, loss = 0.0013\n","t = 200, loss = 0.0058\n","t = 300, loss = 0.0018\n","Starting epoch 77 / 150\n","t = 100, loss = 0.0289\n","t = 200, loss = 0.0141\n","t = 300, loss = 0.0008\n","Starting epoch 78 / 150\n","t = 100, loss = 0.0062\n","t = 200, loss = 0.0291\n","t = 300, loss = 0.0066\n","Starting epoch 79 / 150\n","t = 100, loss = 0.0216\n","t = 200, loss = 0.0126\n","t = 300, loss = 0.0021\n","Starting epoch 80 / 150\n","t = 100, loss = 0.0418\n","t = 200, loss = 0.0210\n","t = 300, loss = 0.0158\n","Starting epoch 81 / 150\n","t = 100, loss = 0.0082\n","t = 200, loss = 0.0263\n","t = 300, loss = 0.0027\n","Checking accuracy on validation set\n","Got 838 / 1000 correct (83.80)\n","Starting epoch 82 / 150\n","t = 100, loss = 0.0059\n","t = 200, loss = 0.0049\n","t = 300, loss = 0.0010\n","Starting epoch 83 / 150\n","t = 100, loss = 0.0168\n","t = 200, loss = 0.0014\n","t = 300, loss = 0.0265\n","Starting epoch 84 / 150\n","t = 100, loss = 0.0072\n","t = 200, loss = 0.0408\n","t = 300, loss = 0.0064\n","Starting epoch 85 / 150\n","t = 100, loss = 0.0188\n","t = 200, loss = 0.0443\n","t = 300, loss = 0.0120\n","Starting epoch 86 / 150\n","t = 100, loss = 0.0042\n","t = 200, loss = 0.0022\n","t = 300, loss = 0.0470\n","Starting epoch 87 / 150\n","t = 100, loss = 0.0502\n","t = 200, loss = 0.0190\n","t = 300, loss = 0.0007\n","Starting epoch 88 / 150\n","t = 100, loss = 0.0305\n","t = 200, loss = 0.0296\n","t = 300, loss = 0.0127\n","Starting epoch 89 / 150\n","t = 100, loss = 0.0019\n","t = 200, loss = 0.0069\n","t = 300, loss = 0.0202\n","Starting epoch 90 / 150\n","t = 100, loss = 0.0464\n","t = 200, loss = 0.0005\n","t = 300, loss = 0.0154\n","Starting epoch 91 / 150\n","t = 100, loss = 0.0013\n","t = 200, loss = 0.0007\n","t = 300, loss = 0.0446\n","Checking accuracy on validation set\n","Got 859 / 1000 correct (85.90)\n","Starting epoch 92 / 150\n","t = 100, loss = 0.0338\n","t = 200, loss = 0.0628\n","t = 300, loss = 0.0529\n","Starting epoch 93 / 150\n","t = 100, loss = 0.0074\n","t = 200, loss = 0.0322\n","t = 300, loss = 0.0016\n","Starting epoch 94 / 150\n","t = 100, loss = 0.0273\n","t = 200, loss = 0.0020\n","t = 300, loss = 0.0005\n","Starting epoch 95 / 150\n","t = 100, loss = 0.0015\n","t = 200, loss = 0.0040\n","t = 300, loss = 0.0252\n","Starting epoch 96 / 150\n","t = 100, loss = 0.0030\n","t = 200, loss = 0.0130\n","t = 300, loss = 0.0010\n","Starting epoch 97 / 150\n","t = 100, loss = 0.0226\n","t = 200, loss = 0.0122\n","t = 300, loss = 0.0448\n","Starting epoch 98 / 150\n","t = 100, loss = 0.0048\n","t = 200, loss = 0.0815\n","t = 300, loss = 0.0004\n","Starting epoch 99 / 150\n","t = 100, loss = 0.0050\n","t = 200, loss = 0.0008\n","t = 300, loss = 0.0008\n","Starting epoch 100 / 150\n","t = 100, loss = 0.0060\n","t = 200, loss = 0.0007\n","t = 300, loss = 0.0050\n","Starting epoch 101 / 150\n","t = 100, loss = 0.0008\n","t = 200, loss = 0.0043\n","t = 300, loss = 0.0326\n","Checking accuracy on validation set\n","Got 846 / 1000 correct (84.60)\n","Starting epoch 102 / 150\n","t = 100, loss = 0.0164\n","t = 200, loss = 0.0302\n","t = 300, loss = 0.0416\n","Starting epoch 103 / 150\n","t = 100, loss = 0.0035\n","t = 200, loss = 0.0299\n","t = 300, loss = 0.0011\n","Starting epoch 104 / 150\n","t = 100, loss = 0.0482\n","t = 200, loss = 0.0064\n","t = 300, loss = 0.0141\n","Starting epoch 105 / 150\n","t = 100, loss = 0.0036\n","t = 200, loss = 0.0395\n","t = 300, loss = 0.0424\n","Starting epoch 106 / 150\n","t = 100, loss = 0.0461\n","t = 200, loss = 0.0012\n","t = 300, loss = 0.0007\n","Starting epoch 107 / 150\n","t = 100, loss = 0.0006\n","t = 200, loss = 0.0004\n","t = 300, loss = 0.0007\n","Starting epoch 108 / 150\n","t = 100, loss = 0.0022\n","t = 200, loss = 0.0032\n","t = 300, loss = 0.0021\n","Starting epoch 109 / 150\n","t = 100, loss = 0.0050\n","t = 200, loss = 0.0228\n","t = 300, loss = 0.0926\n","Starting epoch 110 / 150\n","t = 100, loss = 0.0026\n","t = 200, loss = 0.0112\n","t = 300, loss = 0.0062\n","Starting epoch 111 / 150\n","t = 100, loss = 0.0649\n","t = 200, loss = 0.0059\n","t = 300, loss = 0.0210\n","Checking accuracy on validation set\n","Got 859 / 1000 correct (85.90)\n","Starting epoch 112 / 150\n","t = 100, loss = 0.0075\n","t = 200, loss = 0.0002\n","t = 300, loss = 0.0011\n","Starting epoch 113 / 150\n","t = 100, loss = 0.0226\n","t = 200, loss = 0.0002\n","t = 300, loss = 0.0058\n","Starting epoch 114 / 150\n","t = 100, loss = 0.0112\n","t = 200, loss = 0.0004\n","t = 300, loss = 0.0005\n","Starting epoch 115 / 150\n","t = 100, loss = 0.0038\n","t = 200, loss = 0.0091\n","t = 300, loss = 0.0003\n","Starting epoch 116 / 150\n","t = 100, loss = 0.0012\n","t = 200, loss = 0.0033\n","t = 300, loss = 0.0004\n","Starting epoch 117 / 150\n","t = 100, loss = 0.0008\n","t = 200, loss = 0.0004\n","t = 300, loss = 0.0090\n","Starting epoch 118 / 150\n","t = 100, loss = 0.0563\n","t = 200, loss = 0.0014\n","t = 300, loss = 0.0140\n","Starting epoch 119 / 150\n","t = 100, loss = 0.0107\n","t = 200, loss = 0.0165\n","t = 300, loss = 0.0022\n","Starting epoch 120 / 150\n","t = 100, loss = 0.0026\n","t = 200, loss = 0.0028\n","t = 300, loss = 0.1262\n","Starting epoch 121 / 150\n","t = 100, loss = 0.0889\n","t = 200, loss = 0.0026\n","t = 300, loss = 0.0011\n","Checking accuracy on validation set\n","Got 868 / 1000 correct (86.80)\n","Starting epoch 122 / 150\n","t = 100, loss = 0.0038\n","t = 200, loss = 0.0009\n","t = 300, loss = 0.0475\n","Starting epoch 123 / 150\n","t = 100, loss = 0.0042\n","t = 200, loss = 0.0110\n","t = 300, loss = 0.0007\n","Starting epoch 124 / 150\n","t = 100, loss = 0.0016\n","t = 200, loss = 0.0022\n","t = 300, loss = 0.0176\n","Starting epoch 125 / 150\n","t = 100, loss = 0.0115\n","t = 200, loss = 0.0005\n","t = 300, loss = 0.0019\n","Starting epoch 126 / 150\n","t = 100, loss = 0.0036\n","t = 200, loss = 0.0001\n","t = 300, loss = 0.0009\n","Starting epoch 127 / 150\n","t = 100, loss = 0.0014\n","t = 200, loss = 0.0296\n","t = 300, loss = 0.0007\n","Starting epoch 128 / 150\n","t = 100, loss = 0.0029\n","t = 200, loss = 0.0070\n","t = 300, loss = 0.0019\n","Starting epoch 129 / 150\n","t = 100, loss = 0.0180\n","t = 200, loss = 0.0049\n","t = 300, loss = 0.0004\n","Starting epoch 130 / 150\n","t = 100, loss = 0.0048\n","t = 200, loss = 0.0050\n","t = 300, loss = 0.0042\n","Starting epoch 131 / 150\n","t = 100, loss = 0.0008\n","t = 200, loss = 0.0051\n","t = 300, loss = 0.0010\n","Checking accuracy on validation set\n","Got 834 / 1000 correct (83.40)\n","Starting epoch 132 / 150\n","t = 100, loss = 0.0005\n","t = 200, loss = 0.0029\n","t = 300, loss = 0.0125\n","Starting epoch 133 / 150\n","t = 100, loss = 0.0029\n","t = 200, loss = 0.0012\n","t = 300, loss = 0.0007\n","Starting epoch 134 / 150\n","t = 100, loss = 0.0002\n","t = 200, loss = 0.0025\n","t = 300, loss = 0.0040\n","Starting epoch 135 / 150\n","t = 100, loss = 0.0029\n","t = 200, loss = 0.0006\n","t = 300, loss = 0.0023\n","Starting epoch 136 / 150\n","t = 100, loss = 0.0038\n","t = 200, loss = 0.0016\n","t = 300, loss = 0.0002\n","Starting epoch 137 / 150\n","t = 100, loss = 0.0111\n","t = 200, loss = 0.0010\n","t = 300, loss = 0.0030\n","Starting epoch 138 / 150\n","t = 100, loss = 0.0074\n","t = 200, loss = 0.0108\n","t = 300, loss = 0.0001\n","Starting epoch 139 / 150\n","t = 100, loss = 0.0001\n","t = 200, loss = 0.0113\n","t = 300, loss = 0.0026\n","Starting epoch 140 / 150\n","t = 100, loss = 0.0197\n","t = 200, loss = 0.0014\n","t = 300, loss = 0.0025\n","Starting epoch 141 / 150\n","t = 100, loss = 0.0002\n","t = 200, loss = 0.0259\n","t = 300, loss = 0.0300\n","Checking accuracy on validation set\n","Got 846 / 1000 correct (84.60)\n","Starting epoch 142 / 150\n","t = 100, loss = 0.0524\n","t = 200, loss = 0.0034\n","t = 300, loss = 0.0009\n","Starting epoch 143 / 150\n","t = 100, loss = 0.0002\n","t = 200, loss = 0.0205\n","t = 300, loss = 0.0022\n","Starting epoch 144 / 150\n","t = 100, loss = 0.0142\n","t = 200, loss = 0.0063\n","t = 300, loss = 0.0002\n","Starting epoch 145 / 150\n","t = 100, loss = 0.0255\n","t = 200, loss = 0.0061\n","t = 300, loss = 0.0100\n","Starting epoch 146 / 150\n","t = 100, loss = 0.0003\n","t = 200, loss = 0.0052\n","t = 300, loss = 0.0015\n","Starting epoch 147 / 150\n","t = 100, loss = 0.0006\n","t = 200, loss = 0.0313\n","t = 300, loss = 0.0298\n","Starting epoch 148 / 150\n","t = 100, loss = 0.0313\n","t = 200, loss = 0.0001\n","t = 300, loss = 0.0082\n","Starting epoch 149 / 150\n","t = 100, loss = 0.0103\n","t = 200, loss = 0.0259\n","t = 300, loss = 0.0177\n","Starting epoch 150 / 150\n","t = 100, loss = 0.0629\n","t = 200, loss = 0.0120\n","t = 300, loss = 0.0009\n","Checking accuracy on validation set\n","Got 859 / 1000 correct (85.90)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.859"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"2pcMIzFWPqeY","colab_type":"code","outputId":"d959a357-ffba-45f5-c9ad-6d2093f23bb3","executionInfo":{"status":"ok","timestamp":1588198685377,"user_tz":-480,"elapsed":11482,"user":{"displayName":"517613021@qq.com","photoUrl":"","userId":"10807275253709735297"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["best_model = model\n","check_accuracy(best_model, loader_test)\n","#22:20(epoch==5)~"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Checking accuracy on test set\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Got 8431 / 10000 correct (84.31)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.8431"]},"metadata":{"tags":[]},"execution_count":40}]}]}