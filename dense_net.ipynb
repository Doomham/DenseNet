{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3.5","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"dense_net.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yJxfH7WgPqd6","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np\n","\n","import timeit"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMq1nbJSPyND","colab_type":"code","outputId":"6cd9e4d6-c077-49f2-cff1-537577b76f3e","executionInfo":{"status":"ok","timestamp":1588085198113,"user_tz":-480,"elapsed":23156,"user":{"displayName":"517613021@qq.com","photoUrl":"","userId":"10807275253709735297"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["!wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","!tar xzf cifar-10-python.tar.gz"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-04-28 14:46:17--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170498071 (163M) [application/x-gzip]\n","Saving to: ‘cifar-10-python.tar.gz’\n","\n","cifar-10-python.tar 100%[===================>] 162.60M  15.6MB/s    in 12s     \n","\n","2020-04-28 14:46:29 (13.8 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fwm-IXV1Pqd_","colab_type":"code","colab":{}},"source":["class ChunkSampler(sampler.Sampler):\n","    \"\"\"Samples elements sequentially from some offset. \n","    Arguments:\n","        num_samples: # of desired datapoints\n","        start: offset where we should start selecting from\n","    \"\"\"\n","    def __init__(self, num_samples, start = 0):\n","        self.num_samples = num_samples\n","        self.start = start\n","\n","    def __iter__(self):\n","        return iter(range(self.start, self.start + self.num_samples))\n","\n","    def __len__(self):\n","        return self.num_samples\n","\n","NUM_TRAIN = 49000\n","NUM_VAL = 1000\n","\n","cifar10_train = dset.CIFAR10('/content/', train=True, download=False,\n","                           transform=T.ToTensor())\n","loader_train = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n","\n","cifar10_val = dset.CIFAR10('/content/', train=True, download=False,\n","                           transform=T.ToTensor())\n","loader_val = DataLoader(cifar10_val, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n","\n","cifar10_test = dset.CIFAR10('/content/', train=False, download=False,\n","                          transform=T.ToTensor())\n","loader_test = DataLoader(cifar10_test, batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHobz-oUPqeD","colab_type":"code","colab":{}},"source":["dtype = torch.FloatTensor # the CPU datatype\n","\n","# Constant to control how frequently we print train loss\n","print_every = 100\n","\n","# This is a little utility that we'll use to reset the model\n","# if we want to re-initialize all our parameters\n","def reset(m):\n","    if hasattr(m, 'reset_parameters'):\n","        m.reset_parameters()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eY3afDLuPqeG","colab_type":"code","colab":{}},"source":["class Flatten(nn.Module):\n","    def forward(self, x):\n","        N, C, H, W = x.size() # read in N, C, H, W\n","        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"olw200ViPqeK","colab_type":"code","colab":{}},"source":["# Verify that CUDA is properly configured and you have a GPU available\n","\n","torch.cuda.is_available()\n","gpu_dtype = torch.cuda.FloatTensor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iyNxqMoTPqeN","colab_type":"code","colab":{}},"source":["def train(model, loss_fn, optimizer, num_epochs = 1):\n","    for epoch in range(num_epochs):\n","        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n","        model.train()\n","        for t, (x, y) in enumerate(loader_train):\n","            x_var = Variable(x.type(gpu_dtype))\n","            y_var = Variable(y.type(gpu_dtype).long())\n","\n","            scores = model(x_var)\n","            \n","            loss = loss_fn(scores, y_var)\n","            if (t + 1) % print_every == 0:\n","                print('t = %d, loss = %.4f' % (t + 1, loss.data))\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","def check_accuracy(model, loader):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')   \n","    num_correct = 0\n","    num_samples = 0\n","    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n","    for x, y in loader:\n","        x_var = Variable(x.type(gpu_dtype), volatile=True)\n","\n","        scores = model(x_var)\n","        _, preds = scores.data.cpu().max(1)\n","        num_correct += (preds == y).sum()\n","        num_samples += preds.size(0)\n","    acc = float(num_correct) / num_samples\n","    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSObhSgOPqeR","colab_type":"code","colab":{}},"source":["class Bottleneck(nn.Module):\n","    def __init__(self, in_dims, growth_rate):\n","        super(Bottleneck, self).__init__()\n","        self.block = nn.Sequential(\n","        nn.BatchNorm2d(in_dims),\n","        nn.ReLU(),\n","        nn.Conv2d(in_dims, 4 * growth_rate, kernel_size=1),\n","            \n","        nn.BatchNorm2d(4 * growth_rate),\n","        nn.ReLU(),\n","        nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1))\n","        \n","    def forward(self, x):\n","        out = self.block(x)\n","        #print(x.shape)\n","        #print(out.shape)\n","        out = torch.cat([out, x], 1)\n","        return out\n","\n","class Transition(nn.Module):\n","    def __init__(self, in_dims, out_dims):\n","        super(Transition, self).__init__()\n","        self.trans = nn.Sequential(\n","        nn.BatchNorm2d(in_dims),\n","        nn.ReLU(),\n","        nn.Conv2d(in_dims, out_dims, kernel_size=1),\n","        nn.AvgPool2d(2))\n","    \n","    def forward(self, x):\n","        return self.trans(x)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMstvN8RPqeV","colab_type":"code","outputId":"21806142-92fa-4106-935b-907ee832b8de","executionInfo":{"status":"ok","timestamp":1588087801590,"user_tz":-480,"elapsed":1079009,"user":{"displayName":"517613021@qq.com","photoUrl":"","userId":"10807275253709735297"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["nblocks = [6, 12, 24, 16]\n","learning_rate=0.01\n","\n","class DenseNet(nn.Module):\n","    def __init__(self, block, trans, nblocks, growth_rate=12, theta=0.5, num_classes=10):\n","        super(DenseNet, self).__init__()\n","        \n","        in_dims = 2*growth_rate\n","        self.dense1 = self.dense_block(block, nblocks[0], in_dims, growth_rate)\n","        in_dims += int(nblocks[0] * growth_rate)\n","        out_dims = int(in_dims * theta)\n","        self.trans1 = trans(in_dims, out_dims)\n","        in_dims = out_dims\n","        \n","        self.dense2 = self.dense_block(block, nblocks[1], in_dims, growth_rate)\n","        in_dims += int(nblocks[1] * growth_rate)\n","        out_dims = int(in_dims * theta)\n","        self.trans2 = trans(in_dims, out_dims)\n","        in_dims = out_dims\n","        \n","        self.dense3 = self.dense_block(block, nblocks[2], in_dims, growth_rate)\n","        in_dims += int(nblocks[2] * growth_rate)\n","        out_dims = int(in_dims * theta)\n","        self.trans3 = trans(in_dims, out_dims)\n","        in_dims = out_dims\n","        \n","        self.dense4 = self.dense_block(block, nblocks[3], in_dims, growth_rate)\n","        in_dims += int(nblocks[3] * growth_rate)\n","        \n","        self.dense_net = nn.Sequential(\n","            nn.Conv2d(3, 2 * growth_rate, kernel_size=3, padding=1),\n","            self.dense1,\n","            self.trans1,\n","            self.dense2,\n","            self.trans2,\n","            self.dense3,\n","            self.trans3,\n","            self.dense4,\n","            nn.BatchNorm2d(in_dims),\n","            nn.ReLU(),\n","            nn.AvgPool2d(4),\n","            Flatten(),\n","            nn.Linear(in_dims, num_classes)\n","        )\n","        \n","    def dense_block(self, block, num_blocks, in_dims, growth_rate):\n","        layers = []\n","        for i in range(num_blocks):\n","            layers.append(block(in_dims, growth_rate))\n","            in_dims += growth_rate\n","        return nn.Sequential(* layers)\n","    \n","    def forward(self, x):\n","        #print(x.shape)\n","        out = self.dense_net(x)\n","        return out\n","\n","model = DenseNet(Bottleneck, Transition,nblocks)\n","model.type(gpu_dtype)\n","\n","loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)# lr sets the learning rate of the optimizer\n","train(model, loss_fn, optimizer, num_epochs=10)\n","check_accuracy(model, loader_val)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Starting epoch 1 / 10\n","t = 100, loss = 1.6864\n","t = 200, loss = 1.7229\n","t = 300, loss = 1.6110\n","t = 400, loss = 1.2373\n","t = 500, loss = 1.3040\n","t = 600, loss = 1.1853\n","t = 700, loss = 1.2401\n","Starting epoch 2 / 10\n","t = 100, loss = 0.9661\n","t = 200, loss = 1.0263\n","t = 300, loss = 1.0216\n","t = 400, loss = 0.8074\n","t = 500, loss = 0.9199\n","t = 600, loss = 0.7567\n","t = 700, loss = 0.8148\n","Starting epoch 3 / 10\n","t = 100, loss = 0.7195\n","t = 200, loss = 0.7940\n","t = 300, loss = 0.9014\n","t = 400, loss = 0.5596\n","t = 500, loss = 0.8449\n","t = 600, loss = 0.6544\n","t = 700, loss = 0.7426\n","Starting epoch 4 / 10\n","t = 100, loss = 0.5882\n","t = 200, loss = 0.6705\n","t = 300, loss = 0.7262\n","t = 400, loss = 0.4976\n","t = 500, loss = 0.7047\n","t = 600, loss = 0.6191\n","t = 700, loss = 0.6711\n","Starting epoch 5 / 10\n","t = 100, loss = 0.5267\n","t = 200, loss = 0.5543\n","t = 300, loss = 0.5690\n","t = 400, loss = 0.4282\n","t = 500, loss = 0.6193\n","t = 600, loss = 0.5305\n","t = 700, loss = 0.5804\n","Starting epoch 6 / 10\n","t = 100, loss = 0.4845\n","t = 200, loss = 0.4311\n","t = 300, loss = 0.4392\n","t = 400, loss = 0.3699\n","t = 500, loss = 0.5181\n","t = 600, loss = 0.4243\n","t = 700, loss = 0.5221\n","Starting epoch 7 / 10\n","t = 100, loss = 0.3248\n","t = 200, loss = 0.3687\n","t = 300, loss = 0.4590\n","t = 400, loss = 0.3783\n","t = 500, loss = 0.4036\n","t = 600, loss = 0.3060\n","t = 700, loss = 0.4712\n","Starting epoch 8 / 10\n","t = 100, loss = 0.3109\n","t = 200, loss = 0.3587\n","t = 300, loss = 0.4527\n","t = 400, loss = 0.3216\n","t = 500, loss = 0.3190\n","t = 600, loss = 0.2749\n","t = 700, loss = 0.4472\n","Starting epoch 9 / 10\n","t = 100, loss = 0.1921\n","t = 200, loss = 0.3508\n","t = 300, loss = 0.2789\n","t = 400, loss = 0.2314\n","t = 500, loss = 0.2717\n","t = 600, loss = 0.1910\n","t = 700, loss = 0.3092\n","Starting epoch 10 / 10\n","t = 100, loss = 0.1661\n","t = 200, loss = 0.3147\n","t = 300, loss = 0.1370\n","t = 400, loss = 0.1942\n","t = 500, loss = 0.2036\n","t = 600, loss = 0.1686\n","t = 700, loss = 0.4264\n","Checking accuracy on validation set\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Got 810 / 1000 correct (81.00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2pcMIzFWPqeY","colab_type":"code","outputId":"aa5bf400-cb47-4304-ae51-50e6641d1229","executionInfo":{"status":"ok","timestamp":1588087820904,"user_tz":-480,"elapsed":14817,"user":{"displayName":"517613021@qq.com","photoUrl":"","userId":"10807275253709735297"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["best_model = model\n","check_accuracy(best_model, loader_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Checking accuracy on test set\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Got 8070 / 10000 correct (80.70)\n"],"name":"stdout"}]}]}